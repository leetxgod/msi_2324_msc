\chapter{Introduction}\label{chap:intro}

%https://www.usenix.org/system/files/sec22-turonova.pdf
%https://arxiv.org/abs/2407.20479
%https://www.regular-expressions.info/catastrophic.html

In this chapter, the problem is overviewed, the study's importance is explained along with goals for the proposed solution. 

\section{Background}
Regular expressions are a foundational tool in computer science, widely used in pattern matching, lexical analysis, input validation, and string processing. Their expressiveness and concise syntax make them a powerful language for describing regular languages.

% However, when implemented without care, especially in backtracking-based engines, regular expressions can become a source of serious security vulnerabilities.

A regular expression $R$ is used (along with an input $W$) in regex matching engines. The matching engines will verify if $W$ is fully matched by $R$, meaning that the entire input is a match - or they will verify if a substring of $W$ is matched by $R$. 

% Current matching engines commonly fall into one of the following categories:
% \begin{itemize}
% 	\item \textbf{Finite State Machine Regular Expression Engines}: A finite state machine (or finite \emph{automaton}) is built and evaluated using every symbol $\sigma \in W$. Used \emph{UNIX}-based systems.
% 	\item \textbf{Backtracking Regular Expression Engines}: Instead of building a finite state machine, 
% \end{itemize}

\section{Regular Expression Denial of Service}
One such vulnerability is known as \emph{Regular Expression Denial of Service} (ReDoS). ReDoS exploits the pathological worst-case behavior of certain regular expressions, causing exponential time complexity during matching. In typical backtracking matchers---such as those found in JavaScript, Java, and many scripting environments---ambiguous or nested expressions (especially involving repetition, such as \texttt{(a+)+}) can lead the engine to explore an exponential number of paths for certain crafted inputs. This behavior allows an attacker to intentionally supply inputs that force excessive computation, effectively rendering a service unavailable or degraded.

The root of the ReDoS problem lies not in regular expressions as a theoretical model but in how they are operationalized in software. While deterministic finite automata (DFAs) evaluate regular expressions in linear time, many real-world engines opt for backtracking NFAs due to their flexibility and ease of implementation. Unfortunately, these NFAs are susceptible to exponential blow-up in ambiguous or unguarded patterns.

\section{Case Studies}
\subsection{Stack Overflow}
On the 20th of July 2016, a user published an malformed post on the online information exchange forum \textit{Stack Overflow}. A couple minutes after the post, at around 14:44 UTC, the entire website became unavailable for around 34 minutes, after which there was an update that fixed the underlying issue.

On the forum, there is an automatic text formatter that runs every time someone posts something. This tool will trim unicode spaces from the start of a line until its end. The regular expression responsible for matching these spaces was the following:

\begin{center}
	$\textasciicircum [ \textbackslash s \textbackslash u200c]+|[ \textbackslash s \textbackslash u200c]+\$$
\end{center}

\begin{itemize}
	\item \textbf{$\textasciicircum$} will anchor the following expression to the start of a string
	\item \textbf{$[ \textbackslash s \textbackslash u200c]+$} will match either one whitespace character (space, tab, newline, etc..) or the unicode character U+200C, also known as the \textit{Zero Width Non-Joiner}
	\textit \textbf{$|$} is the union operator, meaning that the expression will match either the left or right side expressions (relative to this operator)
	\item \textbf{$\$$} will anchor the match to the end of that string
\end{itemize}


The automatic text formatter contains a matcher that tried to match the regular expression described above against an input that contained around 20,000 consecutive whitespace characters on one line that started with $--$.
The backtracking matcher in place worked as follows:

Given an input string $M$ of length $\text{len}(M)$, let $n_k$ denote the character at position $k$, where $0 \leq k < \text{len}(M)$. For each possible starting position $p$ such that $0 \leq p < \text{len}(M)$, perform the following steps:

\begin{enumerate}
	\item Check whether the character $n_k$ (for $k \geq p$) belongs to either the character class \verb|\s| (whitespace) or the Unicode character \verb|\u200c| (zero-width non-joiner).
	\item Continue checking characters until a character not in the above classes is encountered or the end of the string is reached.
	\item If the end of the string is reached and all characters from position $p$ onward matched, the pattern succeeds.
	\item If a non-matching character is encountered before the end of the string, the match fails at this position; increment $p$ and repeat from step 1.
\end{enumerate}

For a $20{,}000$ whitespace-character input, the sum of computations is given as follows:

\begin{center}
	\[ \sum_{k=1}^{20,000} k = \frac{20,000 \cdot (20,000) + 1}{2} = 200,010,000 \]
\end{center}

This means that this matching algorithm ran in $O(n^2)$ complexity, and this blow up was to be expected.

%Giv
%
%For a character $n_k$ in the input text $M$ whose position is given by $0 \le k < \text{len(M)}$, start position $0 \le p < \text{len(M)}$.
%\begin{enumerate}
%	\item Check if $n_k$ belongs to either the $\textbackslash s$ or $\textbackslash u200c$ character class
%	\item If $n_k$ doesn't belong, 
%\end{enumerate}

%\begin{enumerate}
%	\item The regex engine attempts to match the expression \verb|^[\s\u200c]+| or \verb|[\s\u200c]+$| against an input string. This pattern is used to trim leading or trailing whitespace and zero-width non-joiner (ZWNJ) characters.
%	
%	\item The second part of the regex \verb|[\s\u200c]+$| tries to match one or more trailing whitespace/ZWNJ characters up to the end of the string.
%	
%	\item The backtracking engine begins from the first space and tries to consume all 20{,}000 whitespace characters, expecting the end of the string immediately after.
%	
%	\item When it finds `--` instead of end-of-string, the match fails, and the engine backtracks:
%	\begin{enumerate}
%		\item It retries the match starting from the second space, then the third, and so on.
%		\item Each attempt involves checking whether the substring from that point matches the pattern ending in \verb|$|.
%	\end{enumerate}
%	
%	\item This leads to a total of:
%	\[
%	\sum_{i=1}^{20{,}000} i = \frac{20{,}000 \cdot 20{,}001}{2} = 200,\!010,\!000
%	\]
%	character class checks, resulting in $O(n^2)$ time complexity.
%	
%	\item This CPU-intensive behavior caused the web server to become unresponsive, triggering a system-wide outage due to the homepage failing health checks.
%	
%	\item The issue was mitigated by replacing the regex with a faster substring-based trimming function.
%\end{enumerate}

%The backtracking matcher begins scanning from the first character of the input. For each position $i$, it attempts to match the entire suffix using the pattern (e.g., $\s+$).
%If the match fails at the end, it backtracks and tries from the next character, leading to $O(n^2)$ complexity when the input consists of long repeated whitespace sequences. This behavior caused severe CPU spikes when the 20,000-space input was processed, triggering a denial-of-service condition.




